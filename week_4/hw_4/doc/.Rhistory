url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
library(XML)
library(RCurl)
data <- list[]
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
library(XML)
library(RCurl)
data <- list[]
data <- list()
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
data <- unlist(data)
data
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
data <- unlist(data)
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index.html', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
data <- unlist(data)
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
for( i in 1058:1118){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
library(XML)
library(RCurl)
data <- list()
for( i in 3650:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
View(data)
data <- unlist(data)
heml
html
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
getdoc <- function(line){
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
if(start != -1 & end != -1){
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='UTF-8')
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][4]
write(doc, gsub('html', 'txt', name))
}
}
sapply(data, getdoc)
library(XML)
library(RCurl)
data <- list()
for( i in 3670:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('www.ptt.cc', url.list, sep=''))
}
data <- unlist(data)
data
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='UTF-8')
start <- regexpr('www', line)[1]
line <- "www.ptt.cc/bbs/StupidClown/M.1538580297.A.A4F.html"
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
start
end
len(line)
nchar(line)
start <- regexpr('www', line)[1]
tmp <- paste(i, '.html', sep='')
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
start
end
nchar(line)
substr("asdasd", 1, 5)
substr("asdasd", 1, 4)
start <- regexpr('www', line)
end <- regexpr('html', line)[1]
start
start <- regexpr('www', line)[2]
end <- regexpr('html', line)[1]
start
start <- regexpr('www', line)[3]
end <- regexpr('html', line)[1]
start
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
start
end <- regexpr('html', line)
start
end
if(start != -1 & end != -1){
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='UTF-8')
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][4]
write(doc, gsub('html', 'txt', name))
}
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='UTF-8')
html
line <- "www.ptt.cc/bbs/StupidClown/M.1538580297.A.A4F.html"
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
start
end
nchar(line)
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='UTF-8')
url
html
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
htdoc
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
View(htdoc)
name <- strsplit(url, '/')[[1]][4]
name <- strsplit(url, '/')
View(name)
name <- strsplit(url, '/')[4]
name <- strsplit(url, '/')[1]
name <- strsplit(url, '/')[1][4]
name <- strsplit(url, '/')[[1]
write(doc, gsub('html', 'txt', name))
}
}
sapply(data, getdoc)
setwd("~/Documents/GitHub/CSX4001/week_4/doc")
name <- strsplit(url, '/')[[1]][4]
name <- strsplit(url, '/')[[1]]
name <- strsplit(url, '/')[1]
View(name)
name <- strsplit(url, '/')[[1]][4]
htdoc <- xpathSApply(html, "//[@id='main-content']", xmlValue)
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='big5')
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='utf-8')
html
line <- "www.ptt.cc/bbs/StupidClown/M.1538580297.A.A4F.html"
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
start
end
nchar(line)
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url), encoding='utf-8')
heml
html
library(XML)
library(RCurl)
tmp <- paste(i, '.html', sep='')
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
html
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url))
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
html <- htmlParse(getURL(url))
html
url <- substr(line, start, end+3)
url
url <- substr(line, start, end+3)
html <- htmlParse(getURL(url))
html
getURL(url)
url <- substr(line, start, end+3)
getURL(url)
line <- "https://www.ptt.cc/bbs/StupidClown/M.1538580297.A.A4F.html"
start <- regexpr('www', line)[1]
end <- regexpr('html', line)[1]
start
end
nchar(line)
if(start != -1 & end != -1){
url <- substr(line, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][4]
write(doc, gsub('html', 'txt', name))
}
url <- substr(line, start, end+3)
getURL(url)
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
for(i in 3670:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
View(data)
library(XML)
library(RCurl)
library(XML)
library(RCurl)
data <- list()
for(i in 3670:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
View(data)
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
for(i in 3670:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
View(data)
data.chr <- unlist(data)
line <- "https://www.ptt.cc/bbs/StupidClown/M.1538580297.A.A4F.html"
start <- regexpr('http', line)[1]
end <- regexpr('html', line)[1]
start
end
start
end
url <- substr(line, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
html
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
htdoc
name <- strsplit(url, '/')[[1]][4]
name <- strsplit(url, '/')[[1]]
name <- strsplit(url, '/')[[1]][6]
write(doc, gsub('html', 'txt', name))
url <- substr(line, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
htdoc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(htdoc, gsub('html', 'txt', name))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(htdoc, gsub('html', 'txt', name))
library(XML)
library(RCurl)
data <- list()
for(i in 3670:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
getdoc <- function(line){
line <- "https://www.ptt.cc/bbs/StupidClown/M.1538580297.A.A4F.html"
start <- regexpr('https', line)[1]
end <- regexpr('html', line)[1]
start
end
nchar(line)
if(start != -1 & end != -1){
url <- substr(line, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(htdoc, gsub('html', 'txt', name))
}
}
sapply(data.chr, getdoc)
start <- regexpr('https', line)[1]
end <- regexpr('html', line)[1]
start
end
url <- substr(line, start, end+3)
library(XML)
library(RCurl)
data <- list()
for(i in 3670:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
getdoc <- function(line){
start <- regexpr('https', line)[1]
end <- regexpr('html', line)[1]
if(start != -1 & end != -1){
url <- substr(line, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(htdoc, gsub('html', 'txt', name))
}
}
sapply(data.chr, getdoc)
library(XML)
library(RCurl)
data <- list()
for(i in 3678:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
data.chr
library(XML)
library(RCurl)
data <- list()
for(i in 3678:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
data.chr
line
getdoc <- function(address){
start <- regexpr('https', address)[1]
end <- regexpr('html', address)[1]
if(start != -1 & end != -1){
url <- substr(address, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(htdoc, gsub('html', 'txt', name))
}
}
sapply(data.chr, getdoc)
sapply(data.chr, getdoc)
sapply(data.chr, getdoc)
View(app)
start <- regexpr('https', address)[1]
end <- regexpr('html', address)[1]
url <- substr(address, start, end+3)
getURL(url)
board
getdoc(data.chr)
setwd("~/Documents/GitHub/CSX4001/week_4/doc")
library(XML)
library(RCurl)
data <- list()
for(i in 3678:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
data.chr
getdoc <- function(address){
start <- regexpr('https', address)[1]
end <- regexpr('html', address)[1]
if(start != -1 & end != -1){
url <- substr(address, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(htdoc, gsub('html', 'txt', name))
}
}
getdoc(data.chr)
View(data)
data.chr
url <- substr(address, start, end+3)
data.chr[1]
getdoc(data.chr[1])
View(getdoc)
View(getdoc)
View(getdoc)
url <- 123
getdoc(data.chr[1])
library(XML)
library(RCurl)
data <- list()
for(i in 3678:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
data.chr
getdoc <- function(address){
start <- regexpr('https', address)[1]
end <- regexpr('html', address)[1]
if(start != -1 & end != -1){
url <- substr(address, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(doc, gsub('html', 'txt', name))
}
}
data.chr[1]
getdoc(data.chr[1])
sapply(data.chr, getdoc)
library(XML)
library(RCurl)
data <- list()
for(i in 3671:3680){
tmp <- paste(i, '.html', sep='')
url <- paste('https://www.ptt.cc/bbs/StupidClown/index', tmp, sep='')
html <- htmlParse(getURL(url))
url.list <- xpathSApply(html, "//div[@class='title']/a[@href]", xmlAttrs)
data <- rbind(data, paste('https://www.ptt.cc', url.list, sep=''))
}
data.chr <- unlist(data)
data.chr
getdoc <- function(address){
start <- regexpr('https', address)[1]
end <- regexpr('html', address)[1]
if(start != -1 & end != -1){
url <- substr(address, start, end+3)
getURL(url)
html <- htmlParse(getURL(url))
doc <- xpathSApply(html, "//div[@id='main-content']", xmlValue)
name <- strsplit(url, '/')[[1]][6]
write(doc, gsub('html', 'txt', name))
}
}
sapply(data.chr, getdoc)
library(tm)
library(tmcn)
library(Rwordseg)
install.packages("Rwordseg")
install.packages("Rwordseg",repos="http://R-Forge.R-project.org)
install.packages("Rwordseg", repos="http://R-Forge.R-project.org)
library(tm)
library(tmcn)
install.packages("Rwordseg", repos="http://R-Forge.R-project.org)
install.packages("Rwordseg")
install.packages("Rwordseg")
data.chr <- unlist(data)
install.packages("rwordseg")
library("wordcloud", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
install.packages("rJava")
library(rJava)
library(rJava)
library(tm)
library(NLP)
library(tm)
library(NLP)
library(tm)
library(tmcn)
library(rJava)
install.packages("rJava")
library(rJava)
